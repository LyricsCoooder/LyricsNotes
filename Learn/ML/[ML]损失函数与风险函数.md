# 损失函数与风险函数

首先引入损失函数与风险函数的概念，损失函数用来度量模型一次预测的好坏，风险函数用来度量平均意义下模型预测的好坏.

#### 损失函数:Loss-function

监督学习问题是在假设空间 $\mathcal F$ 中选取模型 $f$ 作为决策函数，对于给定的输入 $X$，由 $f(X)$ 给出相应的输出 $Y_x$，这个输出的预测值 $f(x)$ 与真实值 $Y$ 可能不一致，这时使用一个损失函数来度量预测错误的程度，损失函数是关于 $f(x)$ 与 $Y$ 的非负实函数，记作 $L({Y,{f(X)}})$ .

##### 常用的损失函数：

0-1损失函数 $L({Y,{f(X)}})$：
$$
L({Y,{f(X)}})=
\begin{cases}
1,&Y\ne f(x)\\
0,&Y=f(x)
\end{cases}
$$

平方损失函数 $L({Y,{f(X)}})$：
$$
L({Y,{f(X)}})=(Y-f(x))^2
$$

绝对值损失函数 $L({Y,{f(X)}})$：
$$
L({Y,{f(X)}})= \abs {Y-f(x)}
$$

对数损失函数 $L({Y,{P(Y|X)}})$：
$$
L({Y,{P(Y|X)}})=-logP(Y|X)
$$



#### 风险函数:Risk-function

损失函数值越小，模型就越好，由于输入，输出 $(X,Y)$ 是随机变量，遵循联合分布 $P(X,Y)$，所以损失函数的期望 $E_p$ 是:
$$
R_{exp}(f)=E_p[L(Y,f(X))]=\int_{x{\times}y}L(Y,f(X))P(X,Y)\,dx\,dy
$$
$R_{exp}(f)$ 是理论上模型 $f(x)$ 关于联合分布 $P(X,Y)$ 的平均意义下的损失，称为风险函数或者期望损失.

学习的目标便是找到最小的 $R_{exp}(f)$，但是由于 $P(X,Y)$ 是未知的，所以 $R_{exp}(f)$ 并不能直接被计算，并且如果 $P(X,Y)$ 是已知的，便不再需要进行监督学习，一方面期望风险最小的学习模型要用到联合分布，而联合分布又是未知的，所以监督学习就成为了病态问题.



#### 经验风险:Empirical-risk

给定一个训练数据集 $T$：
$$
T = \{(x_1,y_1),(x_2,y_2)...(x_N,y_N)\}
$$
模型 $f(X)$ 关于 $T$ 的平均损失被称为经验风险，记作 $R_{emp}$：
$$
R_{emp}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))
$$
风险函数 $R_{exp}(f)$ 是模型关于联合分布的期望损失，经验风险 $R_{emp}(f)$ 是模型关于训练样本集的平均损失，由大数定律可知：

> 大数定律：样本数量越多，则其算术平均值就有越高的概率接近期望值

当 $N$ 趋近于无穷时，风险函数 $R_{exp}(f)$ 趋近于经验风险 $R_{emp}(f)$，所以可以利用经验风险 $R_{emp}(f)$ 去估计期望风险 $R_{exp}(f)$，但是由于现实生活中样本数量有限，甚至过少，所以需要对经验风险 $R_{emp}(f)$ 进行矫正.



#### 经验风险最小化与结构风险最小化

在假设空间 $\mathcal F$，损失函数 $L(y,f(x)$ 以及数据集 $T$ 都确定的情况下，经验风险 $R_{emp}f(x)$ 就可以被确定，经验风险最小化策略认为，经验风险最小的模型是最优的模型，按照这一策略最优模型 $f_{best}$为：
$$
f_{best}=\underset{f\in \mathcal F}{min}\,R_{emp}(f) = \underset{f\in \mathcal F}{min}\,\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))
$$
在样本数量足够大的情况下，经验风险最小化策略可以保证很好的学习效果，但是当样本数量不足时，就会产生 ”过拟合“ 现象，为了解决这种问题，结构风险最小化策略被提出，等价于正则化.

> 正则化：是指为解决适定性问题或过拟合而加入额外信息的过程.

结构风险最小化策略在经验风险上加上表示模型复杂度的正则项(*惩罚项*) $\lambda J(f)$，在假设空间 $\mathcal F$，损失函数 $L(y,f(x)$ 以及数据集 $T$ 都确定的情况下，风险结构定义是：
$$
R_{srm}(f)=R_{emp}(f)+\lambda J(f) =\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i)) + \lambda J(f)
$$
其中 $J(f)$ 表示模型的复杂度，是定义在在假设空间 $\mathcal F$ 上的泛函数，模型 $f$ 越复杂，复杂度 $J(f)$ 就越大，反之亦然，也就是说复杂度表示了对该模型的惩罚，$\lambda \ge 0$ 是系数，用来权衡经验风险和模型复杂度.

结构风险最小化策略需要经验风险和模型复杂度同时小，按照这一策略最优模型 $f_{best}$为：
$$
f_{best}=\underset{f\in \mathcal F}{min}\,({R_{emp}(f)+ \lambda J(f)})= \underset{f\in \mathcal F}{min}\,(\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i)+\lambda J(f))
$$
由此监督学习问题便转化成了经验风险和结构风险函数的最优化问题.

 
