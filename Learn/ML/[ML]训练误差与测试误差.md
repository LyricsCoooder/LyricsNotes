# 训练误差与测试误差

当损失函数给定时，基于损失函数的模型的训练误差与测试误差，很自然的就成为了评估该学习方法的标准，但是统计学习中，测试的损失函数与训练的损失函数不一定是相同的损失函数，当然，让两者一致是比较理想的状态.

#### 训练误差

假设学习到的模型是 $Y=\hat f(X)$，训练误差是模型 $Y=\hat f(X)$ 关于训练数据集的平均损失，该数据集容量为 $N$ :
$$
R_{emp}(\hat f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,\hat f(x_i))
$$

#### 测试误差

测试误差是模型 $Y=\hat f(X)$ 关于测试数据集的平均损失，该数据集容量为 $N’$ :
$$
e_{test}=\frac{1}{N'}\sum_{i=1}^{N'}L(y_i,\hat f(x_i))
$$
例如，当损失函数是 ”0-1损失函数” 时，测试误差就变成了测试集上的误差率:
$$
e_{test}=\frac{1}{N'}\sum_{i=1}^{N'}I(y_i \ne\hat f(x_i))
$$
相应的，测试集上的准确率为：
$$
r_{test}=\frac{1}{N'}\sum_{i=1}^{N'}I(y_i =\hat f(x_i))
$$
显然 $e_{test}+r_{test}=1$ .

训练误差和测试误差反应了模型在不同阶段的性能，测试误差反应了学习方法对未知的测试数据集的预测能力，被称为泛化能力.

